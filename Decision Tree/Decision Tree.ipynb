{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'PRML\\\\penguins.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f3fc2bfd6627>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#1 preprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PRML\\penguins.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PRML\\\\penguins.csv'"
     ]
    }
   ],
   "source": [
    "#1 preprocessing\n",
    "data=pd.read_csv('penguins.csv')\n",
    "row=[]\n",
    "c=data.loc[:, data.isnull().any()].columns\n",
    "for i in c:\n",
    "    for j in range(len(data[i])):\n",
    "        if(pd.isna(data[i][j])==True):\n",
    "            row.append(j)\n",
    "row=set(row) \n",
    "data=data.drop(row)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "l=[]\n",
    "for i in data:\n",
    "    if data.dtypes[i]=='object':\n",
    "        l.append(i)\n",
    "        data[i]=le.fit_transform(data[i])    \n",
    "li=[]\n",
    "index=0\n",
    "for i in data:\n",
    "    if data[i].dtype=='float64':\n",
    "        li.append(index)\n",
    "        index+=1\n",
    "    else:\n",
    "        index+=1         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualisation\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(data[data.columns],figsize=(25,25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(data, hue = \"species\", palette=\"Set2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=data,x=\"flipper_length_mm\", y=\"bill_depth_mm\",hue=\"species\")\n",
    "sns.relplot(data=data,x=\"bill_depth_mm\", y=\"bill_length_mm\",hue=\"species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 cost function\n",
    "def gini_index(y):\n",
    "    a,counts = np.unique(y,return_counts=True)\n",
    "\n",
    "    probabilities = counts/counts.sum()\n",
    "    gini = sum(probabilities**2)\n",
    "    return 1-gini\n",
    "def info_gain(parent,left,right):\n",
    "    p_left = len(left) / len(parent)\n",
    "    p_right = len(right) / len(parent)\n",
    "    return gini_index(parent) - (p_left*gini_index(left) + p_right*gini_index(right))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3continuous variables converted to categorical variables first.\n",
    "def cont_to_cat(y,data1):\n",
    "    thre=0\n",
    "    gain=-1000\n",
    "    j=0\n",
    "    y1=data1[:,y]\n",
    "    y1=np.unique(y1)\n",
    "    while(j<len(y1)):\n",
    "        left = np.array([row for row in data1 if row[y]<=y1[j]])\n",
    "        right = np.array([row for row in data1 if row[y]>y1[j]])\n",
    "        parent=data1[:,0]        \n",
    "        curr_info_gain =info_gain(parent, left, right)\n",
    "        if(curr_info_gain>gain):\n",
    "            gain=curr_info_gain\n",
    "            thre=y1[j]\n",
    "        j+=1     \n",
    "    for row in data1:\n",
    "        if(row[y]<=thre):\n",
    "            row[y]=1\n",
    "        else:\n",
    "            row[y]=0\n",
    "    return data1\n",
    "       \n",
    "data=np.array(data)\n",
    "for i in li:\n",
    "    data=cont_to_cat(i,data)\n",
    "print(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree formation\n",
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        self.value = value\n",
    "def best_split(dataset, num_features):\n",
    "        bestsplit = {}\n",
    "        gain = -2000000\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            thresholds = np.unique(feature_values)\n",
    "            for i in thresholds:\n",
    "                left = np.array([row for row in dataset if row[feature_index]<=i])\n",
    "                right = np.array([row for row in dataset if row[feature_index]>i])\n",
    "                if len(left)>0 and len(right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], left[:, -1], right[:, -1]\n",
    "                    curr_info_gain = info_gain(y, left_y, right_y)\n",
    "                    if curr_info_gain>gain:\n",
    "                        bestsplit[\"feature_index\"] = feature_index\n",
    "                        bestsplit[\"threshold\"] = i\n",
    "                        bestsplit[\"left\"] = left\n",
    "                        bestsplit[\"right\"] = right\n",
    "                        bestsplit[\"info_gain\"] = curr_info_gain\n",
    "                        gain = curr_info_gain\n",
    "        return bestsplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tree(dataset, curr_depth=0,max_depth=10,min_samples_split=3):\n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "        if num_samples>=min_samples_split and curr_depth<=max_depth:\n",
    "            bestsplit = best_split(dataset, num_features)\n",
    "            if(bestsplit!={}):\n",
    "                if bestsplit[\"info_gain\"]>0:\n",
    "                    left_subtree = tree(bestsplit[\"left\"], curr_depth+1)\n",
    "                    right_subtree = tree(bestsplit[\"right\"], curr_depth+1)\n",
    "                    return Node(bestsplit[\"feature_index\"], bestsplit[\"threshold\"], left_subtree, right_subtree, bestsplit[\"info_gain\"])\n",
    "\n",
    "        Y = list(Y)\n",
    "        leaf=max(Y, key=Y.count)\n",
    "        return Node(value=leaf)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction on testing data and finding its accuracy\n",
    "def predict(x,root):\n",
    "    if root.value!=None: \n",
    "        return root.value\n",
    "    feature_val = x[root.feature_index]\n",
    "    if feature_val<=root.threshold:\n",
    "        return predict(x, root.left)\n",
    "    else:\n",
    "        return predict(x, root.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 1:]\n",
    "Y = data[:, 0]\n",
    "Y=Y.reshape(len(Y),1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=47)\n",
    "dataset = np.concatenate((X_train, Y_train), axis=1)\n",
    "root =tree(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions=[predict(i,root) for i in X_test]\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_wise accuracy\n",
    "c0=0\n",
    "c0_p=0\n",
    "c1=0\n",
    "c1_p=0\n",
    "c2=0\n",
    "c2_p=0\n",
    "for i in range(len(Y_test)):\n",
    "    if(Y_test[i]==0):\n",
    "        c0+=1\n",
    "        if(predictions[i]==0):\n",
    "            c0_p+=1\n",
    "    if(Y_test[i]==1):\n",
    "        c1+=1\n",
    "        if(predictions[i]==1):\n",
    "            c1_p+=1        \n",
    "    if(Y_test[i]==2):\n",
    "        c2+=1\n",
    "        if(predictions[i]==2):\n",
    "            c2_p+=1   \n",
    "print((c0_p/c0+c1_p/c1+c2_p/c2)/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1 preprocessing\n",
    "data1=pd.read_csv('ENB2012_data.csv')\n",
    "row=[]\n",
    "c=data1.loc[:, data1.isnull().any()].columns\n",
    "for i in c:\n",
    "    for j in range(len(data1[i])):\n",
    "        if(pd.isna(data1[i][j])==True):\n",
    "            row.append(j)\n",
    "row=set(row) \n",
    "data1=data1.drop(row)\n",
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "def data_splitting(dataset):\n",
    "    X_train,X_rem=train_test_split(dataset,train_size=0.7,random_state=41)\n",
    "    X_test,X_valid=train_test_split(X_rem,train_size=0.67,random_state=41)\n",
    "    return X_train,X_test,X_valid\n",
    "\n",
    "a,b_test,c=data_splitting(data1)\n",
    "print(a)\n",
    "print(b_test)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 hyper-parameter tuning \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "mse1=[]\n",
    "max_depth1=[]\n",
    "md=0\n",
    "b=10000\n",
    "for max_depth in range(1,50):\n",
    "    regressor = DecisionTreeRegressor(max_depth=max_depth) \n",
    "    regressor.fit(a.iloc[:,:-1], a.iloc[:,-1])\n",
    "    y_pred = regressor.predict(c.iloc[:,:-1])\n",
    "    y_v=np.array(c.iloc[:,-1])\n",
    "    mse=mean_squared_error(y_v, y_pred)\n",
    "    mse1.append(mse)\n",
    "    max_depth1.append(max_depth)\n",
    "    if(mse<b):\n",
    "        b=mse\n",
    "        md=max_depth\n",
    "plt.figure(figsize=(10,10))\n",
    "fig2 = plt.plot( max_depth1,mse1, linestyle='solid')\n",
    "print(b)\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"max_depth\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse2=[]\n",
    "max_leaf1=[]\n",
    "md=0\n",
    "mln=0\n",
    "b1=10000\n",
    "for i in range(2,150):\n",
    "    regressor = DecisionTreeRegressor(max_leaf_nodes=i) \n",
    "    regressor.fit(a.iloc[:,:-1], a.iloc[:,-1])\n",
    "    y_pred = regressor.predict(c.iloc[:,:-1])\n",
    "    y_v=np.array(c.iloc[:,-1])\n",
    "    mse=mean_squared_error(y_v, y_pred)\n",
    "    mse2.append(mse)\n",
    "    max_leaf1.append(i)\n",
    "    if(mse<b1):\n",
    "        b1=mse\n",
    "        mln=i\n",
    "plt.figure(figsize=(10,10))\n",
    "fig2 = plt.plot( max_leaf1, mse2,linestyle='solid')\n",
    "print(b1)\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"max_leaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse3=[]\n",
    "min_sample1=[]\n",
    "mss=0\n",
    "b2=10000\n",
    "for i in range(2,50):\n",
    "    regressor = DecisionTreeRegressor(min_samples_split=i) \n",
    "    regressor.fit(a.iloc[:,:-1], a.iloc[:,-1])\n",
    "    y_pred = regressor.predict(c.iloc[:,:-1])\n",
    "    y_v=np.array(c.iloc[:,-1])\n",
    "    mse=mean_squared_error(y_v, y_pred)\n",
    "    mse3.append(mse)\n",
    "    min_sample1.append(i)\n",
    "    if(mse<b2):\n",
    "        b2=mse\n",
    "        mss=i\n",
    "plt.figure(figsize=(10,10))\n",
    "fig2 = plt.plot( min_sample1,mse3, linestyle='solid')\n",
    "print(b2)\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"min_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse4=[]\n",
    "min_leaf1=[]\n",
    "msl=0\n",
    "b3=10000\n",
    "for i in range(2,50):\n",
    "    regressor = DecisionTreeRegressor(min_samples_leaf=i) \n",
    "    regressor.fit(a.iloc[:,:-1], a.iloc[:,-1])\n",
    "    y_pred = regressor.predict(c.iloc[:,:-1])\n",
    "    y_v=np.array(c.iloc[:,-1])\n",
    "    mse=mean_squared_error(y_v, y_pred)\n",
    "    mse4.append(mse)\n",
    "    min_leaf1.append(i)\n",
    "    if(mse<b3):\n",
    "        b3=mse\n",
    "        msl=i\n",
    "plt.figure(figsize=(10,10))\n",
    "fig2 = plt.plot( min_leaf1,mse4, linestyle='solid')\n",
    "print(b3)\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"min_leaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mse5=[]\n",
    "max_depth2=[]\n",
    "max_leaf2=[]\n",
    "min_sample2=[]\n",
    "min_leaf2=[]\n",
    "md1=0\n",
    "mln1=0\n",
    "mss1=0\n",
    "msl1=0\n",
    "b_main=10000\n",
    "for max_depth in range(3,20):\n",
    "    for max_leaf in range(30,90):\n",
    "        for min_sample in range(2,10):\n",
    "            for min_leaf in range(2,5):\n",
    "                regressor = DecisionTreeRegressor(max_depth=max_depth,max_leaf_nodes=max_leaf,min_samples_split=min_sample,min_samples_leaf=min_leaf,random_state=41)\n",
    "                regressor.fit(a.iloc[:,:-1], a.iloc[:,-1])\n",
    "                y_pred = regressor.predict(c.iloc[:,:-1])\n",
    "                y_v=np.array(c.iloc[:,-1])\n",
    "                mse=mean_squared_error(y_v, y_pred)\n",
    "                mse5.append(mse)\n",
    "                max_depth2.append(max_depth)\n",
    "                min_leaf2.append(min_leaf)\n",
    "                max_leaf2.append(max_leaf)\n",
    "                min_sample2.append(min_sample)\n",
    "                if(mse<b_main):\n",
    "                    b_main=mse\n",
    "                    md1=max_depth\n",
    "                    mln1=max_leaf\n",
    "                    mss1=min_sample\n",
    "                    msl1=min_leaf\n",
    "print(b_main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3 5-fold cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "regressor = DecisionTreeRegressor(max_depth=md1,max_leaf_nodes=mln1,min_samples_split=mss1,min_samples_leaf=msl1,random_state=41)\n",
    "kfold = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "scores = cross_val_score(regressor, b_test.iloc[:,:-1], b_test.iloc[:,-1],scoring=\"neg_mean_squared_error\", cv=kfold)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image of tree on testing data\n",
    "from sklearn import tree\n",
    "regressor.fit(b_test.iloc[:,:-1], b_test.iloc[:,-1])\n",
    "fig = plt.figure(figsize=(175,175))\n",
    "a = tree.plot_tree(regressor, filled=True,fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
